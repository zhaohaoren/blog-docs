# 【大数据】大数据的那些组件

大数据的组件太多了，有时候我们只有空闲学部分组件，但是对很多组件都不是很清楚，以至于在某些项目中的场景下，我们可能不知所措或者不知道使用哪个组件来切入这个业务场景。所以想做一个组件名单，用来粗略了解下各个组件的作用。也适合初入门大数据的人对全局做一个宏观的了解。

这里只收录我在学习大数据过程中所有的组件，**只是简要介绍他们的作用，在大数据生态圈中的角色**。缺少的后面不断学习不断补充（我等**小白专用**）。

## Hadoop 

![hadoop-logo](D:\workspace\blog-docs\docs\大数据-组件概要\hadoop-logo.jpg)

> 一个分布式文件系统，用来存储数据。

Hadoop的概念可以大可小，大可以是一个生态圈，所有大数据的产品基本都和他有关联。 小指的其实就是Hadoop的存储系统HDFS，这里只介绍HDFS。（Hadoop项目包含了HDFS，MapReduce，Yarn三个项目，旨在解决大数据的所有的问题：存储，计算，资源调度）

**HDFS：Hadoop分布式文件系统**

HDFS的文件系统可以先粗糙的理解为你操作系统上的文件系统一样：我们挂在一个磁盘后，就相当于一块空间加入了我们的文件系统，然后对这个磁盘我们可以创建目录，目录下面存放文件等等。（需要好好理解**文件系统**这个概念）Hadoop也是这样，在Hadoop里面也有文件夹，里面存放路径，这些文件都是Hadoop管理。

你可以理解他就是套在操作系统上的一个独立的文件系统，但是他是分布式的！因为大数据嘛，数据大的一个机子放不下，我们就需要分布式的存储：**把大的文件切块**（比如切成128M一块），然后将这些块分散到这个集群的各个机子上去。

大数据的数据安全也重要，所以HDFS提供了**数据备份-副本的的机制**，这样你一个机器挂了（硬件的损坏，老化等事故是一种常态），别的机器还存留着数据。

简单来说，大数据的数据存到文件里面，然后文件交给Hadoop来管理，Hadoop**主要**负责数据分片分布，副本备份。



## MapReduce

> 一个分布式计算框架。

上面Hadoop说了，是存储数据的，数据是死的，只有挖掘这些数据，才能让数据变得有价值。MapReduce就是来做这个的：**分布式的计算这些数据得出统计结果**。MapReduce和Hadoop是一个项目下的（你下载了Hadoop包，里面就包含了MapReduce，以及下面的Yarn）。

**为什么要有这个？**

大数据的数据大，所以需要分布式。同样的，对数据的计算也不是单机能完成的，所以也要分布式！但是开发一个分布式的应用，不是一件简单的事情！我们如果都自己写的话，要考虑很多东西：任务的分发，任务失败的处理策略等等，这些都让我们自己去写，得累死，也会严重拖慢工作效率（时间就是金钱）。所以这个框架诞生了！他可以让我们**像开发一个非分布式应用那样去开发一个分布式应用。我们只需要写对应的计算逻辑，具体的分布式相关的东西全都交给框架来完成。**这大大方便了我们开发。

**MapReduce的编程模型**

和名字一样，一般2个阶段：Map阶段，Reduce阶段。Map就是分而治之，每个机器负责一小块计算。Reduce就是将数据计算的结果再归整起来。详细的就不细说了，开发一个MapReduce应用很简单，可以自己查阅。

**淘汰论**

确实MapReduce有种种缺陷，不是那么的火了。随着Spark，Flink这些内存计算框架崛起，MapReduce逐渐退居幕后。但是MapReduce依然总会是死而不僵的状态。**每个技术都有自己的适用场景，很少有绝对的好坏！（我只说很少，现在技术爆炸，确实有些技术是相比下绝对坏的）说MapReduce慢，那么MapReduce就适合那些速度要求不高的场景。** 如果你学习大数据，想学学思想可以好好看看MapReduce，但是如果只是用用，确实MapReduce不要花那么多精力，多去看看Spark，Flink。对面试更友好写。



## Yarn

> 英文全称：Yet Another Resource Negotiator，另一种资源协调者。就是一个作业调度和集群资源管理的一个框架。用来管理集群中CPU，内存这些，从而更好的对资源进行分配。

在分布式场景下，**我们集群的所有机器应该被视为一个整体，这些机器所有的资源应该被统一的管理和分配，这样才能最大化的利用好我们的集群**。就**相当于Yarn是一个全局性的操作系统**，这个操作系统管理的是集群下所有的机子。

这个也可以联想一下我们Windows上的资源管理器（虽然有点不确切）。Yarn管理我们操作系统的资源，以及运行在操作系统上的任务（MapReduce任务等）。他管理调度着任务（这个MapReduce任务应该发给那些个机器？），同时也负责分配这些个MapReduce任务需要的内存，CPU资源。

他是一个通用的资源管理和任务调度系统！所以他可以作为资源管理的组件给其他的东西使用，比如Spark这些。当然也有和他功能相同的一些组件，比如Mesos等，可以让你根据你的场景自由搭配这些组件。



## Zookeeper

![image-20200808165007388](D:\workspace\blog-docs\docs\大数据-组件概要\zookeeper.png)



顾名思义：动物管理员。Hadoop生态圈的都是一群小动物，Zookeeper负责管理这些小动物（实际谈不上管理）。



## Hive

![Apache Hive](https://hive.apache.org/images/hive_logo_medium.jpg)

Hive是一个数据分析工具。让我们可以使用SQL来对底层的Hadoop文件进行统计分析。他本质就是一堆MR程序，然后将我们SQL解析成MR任务，然后去Hadoop上查询数据并计算。

SQL的意义咱不多说了。对于很多数据分析师而言，他们不懂编程啊，让他们去写MR程序来计算出他们想要的结果，不现实！所以SQL是必须要有的！ **而且只能说直到目前，对于数据处理来说，SQL的便利性和表达力一直都处于统治地位。你可以看看最新最火的大数据组件，比如Spark，Flink这些，他们都会提供对SQL的支持！**

没学Hive之前，我总误认为是一个基于Hadoop的表。Hive他主要就是一个工具，一个程序包，将SQL解析成MapReduce程序然后放到Yarn这样的资源调度器上计算出结果。只要Hadoop底层存储的文件符合一定的格式，我们就可以按照表的形式来处理他（每个表对应的格式等相关信息，Hive通过存储元数据来关联）。也就是说：**一定格式的文件**，**元数据**，**SQL解析成MapReduce程序**共同组成了Hive。他的核心在于SQL解析成MapReduce，而不是数据的存储（不像MySQL这些数据库一样，底层存储还有一堆的逻辑）。

Hive主要是用来做离线数据分析的，因为他是基于MapReduce的，所以很慢！你要生成个报表给领导看看啥的，可以使用。不能拿它做实时的业务查询。数据分析师什么的用的会多一些。学Hive的重点也是学SQL编程。



## Impala

## Flume

## Kafka

## HBase

## Sqoop

## Kylin

## Oozie

## Azkaban

## Spark

## Flink

## ElasticSearch（ELK）

## ClickHouse

## Kettle

## Hue

## Ambari